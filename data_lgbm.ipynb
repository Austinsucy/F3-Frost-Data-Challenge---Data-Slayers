{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d402b06f-979e-43cf-bb1f-5d6ceadbca2a",
   "metadata": {},
   "source": [
    "# ðŸ“ˆ Fetch and Clean Dataset: F3 Innovate Frost Risk Forecasting\n",
    "- **Converted File to Df** so I could use data\n",
    "- **Dictionary of Name -> Data** such that each station name maps to it's historic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2c302c-a255-4683-a149-96e142d5f58b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install pandas # If Pandas is not already Installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35901902-9878-4c4f-bbcb-f878163fe200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "def file_to_df(file_name: str):\n",
    "    # Load CSV file into a pandas DataFrame\n",
    "    return pd.read_csv(file_name)\n",
    "\n",
    "DATA_DIR = \"../cimis-hourly-data-multiple-stations/\"\n",
    "def get_datasets():\n",
    "    !touch buffer.tmp\n",
    "    !(ls $DATA_DIR | grep \"csv\") > buffer.tmp\n",
    "    name_to_data = dict() # Dictionary for Name to Data\n",
    "    # Read the buffer.tmp and create Name to Data pairs\n",
    "    with open(\"buffer.tmp\", \"r\") as file:\n",
    "        contents = [f for f in file.read().split(\"\\n\") if f]\n",
    "        for content in contents:\n",
    "            file_name = content.split(\".\")[0]\n",
    "            if \"all\" not in file_name:\n",
    "                name_to_data[file_name] = file_to_df(DATA_DIR + content)\n",
    "            \n",
    "        !rm -f buffer.tmp\n",
    "        return name_to_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31158d6e-da0e-456d-8264-3f4fb709d460",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = get_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6219d00-ab8d-4320-b349-f6855551a300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual Data Sets\n",
    "dataset_names = [d for d in datasets.keys() if \"all\" not in d]\n",
    "# Remove columns that contain \"qc\"\n",
    "columns_to_remove = [col for col in datasets['80-fresnostate'].columns.tolist() if \"qc\" in col]\n",
    "for name in datasets:\n",
    "    datasets[name].drop(columns=columns_to_remove, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b107469b-fe2a-4aff-ac13-7eb4201bf195",
   "metadata": {},
   "source": [
    "# ðŸ”¦ LightGBM Integration: Calibrated Frost Probabilities + Temperature Forecasts\n",
    "- **Calibrated classification** models for frost within 3/6/12/24 hours (Isotonic).\n",
    "- **Regression** models (and optional quantiles) for temperature at +H hours.\n",
    "- Utilities that respect time ordering (no leakage)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c296aa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If LightGBM isn't installed in your environment, uncomment and run:\n",
    "!pip install lightgbm\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912d09fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import brier_score_loss, roc_auc_score, average_precision_score, mean_absolute_error\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Ensure timestamp column\n",
    "def ensure_timestamp(df, date_col=\"Date\", hour_col=\"Hour (PST)\"):\n",
    "    if \"timestamp\" in df.columns:\n",
    "        return df.copy()\n",
    "    dfx = df.copy()\n",
    "    if date_col in dfx.columns and hour_col in dfx.columns:\n",
    "        # Parse date\n",
    "        dt = pd.to_datetime(dfx[date_col], errors=\"coerce\")\n",
    "        hr_raw = pd.to_numeric(dfx[hour_col], errors=\"coerce\").fillna(0)\n",
    "        hr = np.where(hr_raw > 23, (hr_raw/100).astype(int), hr_raw.astype(int))\n",
    "        dfx[\"timestamp\"] = dt + pd.to_timedelta(hr, unit=\"h\")\n",
    "    else:\n",
    "        raise ValueError(\"Need either 'timestamp' or Date + Hour (PST) columns.\")\n",
    "    return dfx\n",
    "\n",
    "def make_features(df):\n",
    "    df = df.sort_values(\"timestamp\").copy()\n",
    "    df[\"dewpoint_dep\"] = df[\"Air Temp (C)\"] - df[\"Dew Point (C)\"]\n",
    "    df[\"is_night\"] = (df[\"Sol Rad (W/sq.m)\"] < 50).astype(int)\n",
    "    df[\"is_calm\"]  = (df[\"Wind Speed (m/s)\"] < 3).astype(int)\n",
    "    hour = pd.to_numeric(df[\"Hour (PST)\"], errors=\"coerce\").fillna(0) % 24\n",
    "    angle = 2*np.pi*hour/24.0\n",
    "    df[\"hour_sin\"] = np.sin(angle); df[\"hour_cos\"] = np.cos(angle)\n",
    "    for col in [\"Air Temp (C)\",\"Dew Point (C)\",\"Wind Speed (m/s)\",\"Rel Hum (%)\",\"Sol Rad (W/sq.m)\"]:\n",
    "        df[f\"{col}_lag1\"] = df[col].shift(1)\n",
    "        df[f\"{col}_lag3\"] = df[col].shift(3)\n",
    "        df[f\"{col}_lag6\"] = df[col].shift(6)\n",
    "    df[\"temp_roll_min_6h\"] = df[\"Air Temp (C)\"].rolling(6).min()\n",
    "    df[\"temp_change_3h\"]   = df[\"Air Temp (C)\"] - df[\"Air Temp (C)\"].shift(3)\n",
    "    return df\n",
    "\n",
    "def add_targets(df, H):\n",
    "    df[f\"frost_{H}h\"] = (df[\"Air Temp (C)\"].shift(-H) < 0).astype(int)\n",
    "    df[f\"temp_{H}h\"]  =  df[\"Air Temp (C)\"].shift(-H)\n",
    "    return df\n",
    "\n",
    "BASE_FEATURES = [\n",
    "    \"Air Temp (C)\",\"Dew Point (C)\",\"Rel Hum (%)\",\"Wind Speed (m/s)\",\"Sol Rad (W/sq.m)\",\"Soil Temp (C)\",\n",
    "    \"dewpoint_dep\",\"is_night\",\"is_calm\",\"hour_sin\",\"hour_cos\",\n",
    "    \"Air Temp (C)_lag1\",\"Air Temp (C)_lag3\",\"Air Temp (C)_lag6\",\n",
    "    \"Dew Point (C)_lag1\",\"Wind Speed (m/s)_lag1\",\"Rel Hum (%)_lag1\",\n",
    "    \"temp_roll_min_6h\",\"temp_change_3h\"\n",
    "]\n",
    "\n",
    "# --- helpers you can paste next to your existing code ---\n",
    "def sanitize_columns(df):\n",
    "    # Avoid LightGBM whitespace warning & keep names consistent\n",
    "    return df.rename(columns=lambda c: c.replace(\" \", \"_\"))\n",
    "\n",
    "def build_xy(df_raw, H, feature_cols=None):\n",
    "    \"\"\"\n",
    "    Turn a raw station DataFrame into (X, y_frost, y_temp) for horizon H.\n",
    "    Uses your ensure_timestamp -> make_features -> add_targets pipeline.\n",
    "    If feature_cols is given, uses that exact column set/order (important for cross-station tests).\n",
    "    Otherwise it uses BASE_FEATURES that exist in the frame.\n",
    "    \"\"\"\n",
    "    df = ensure_timestamp(df_raw)\n",
    "    df = make_features(df)\n",
    "    df = add_targets(df, H)\n",
    "\n",
    "    # sanitize names after feature engineering\n",
    "    df = sanitize_columns(df)\n",
    "\n",
    "    # map BASE_FEATURES to sanitized names\n",
    "    base = [c.replace(\" \", \"_\") for c in BASE_FEATURES]\n",
    "\n",
    "    if feature_cols is None:\n",
    "        feature_cols = [c for c in base if c in df.columns]\n",
    "\n",
    "    # targets (sanitized names too)\n",
    "    frost_col = f\"frost_{H}h\"\n",
    "    temp_col  = f\"temp_{H}h\"\n",
    "\n",
    "    needed = feature_cols + [frost_col, temp_col]\n",
    "    df = df.dropna(subset=[c for c in needed if c in df.columns])\n",
    "\n",
    "    X = df[feature_cols]\n",
    "    y_frost = df[frost_col].astype(int)\n",
    "    y_temp  = df[temp_col].astype(float)\n",
    "    return X, y_frost, y_temp, feature_cols\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbae828",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_for_horizon_simple(df, H=6, verbose=True):\n",
    "    # Build features/targets with your existing helpers\n",
    "    X, y_frost, y_temp, feat_cols = build_xy(df, H)  # uses ensure_timestamp -> make_features -> add_targets\n",
    "\n",
    "    # Time-ordered split: 70% train, 15% calibration, 15% test\n",
    "    n = len(X)\n",
    "    i_tr, i_cal = int(n * 0.70), int(n * 0.85)\n",
    "\n",
    "    X_tr, y_tr = X.iloc[:i_tr], y_frost.iloc[:i_tr]\n",
    "    X_cal, y_cal = X.iloc[i_tr:i_cal], y_frost.iloc[i_tr:i_cal]\n",
    "    X_te,  y_te  = X.iloc[i_cal:],      y_frost.iloc[i_cal:]\n",
    "    y_temp_trcal = y_temp.iloc[:i_cal]\n",
    "    y_temp_te    = y_temp.iloc[i_cal:]\n",
    "\n",
    "    # --- Classifier ---\n",
    "    clf = lgb.LGBMClassifier(\n",
    "        n_estimators=600,\n",
    "        learning_rate=0.05,\n",
    "        class_weight=\"balanced\",  # simpler than manual scale_pos_weight\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.9,\n",
    "        random_state=42\n",
    "    )\n",
    "    clf.fit(X_tr, y_tr)\n",
    "\n",
    "    # Probability calibration on the calibration window (avoids cv='prefit' deprecation)\n",
    "    calib = CalibratedClassifierCV(base_estimator=clf, method=\"isotonic\", cv=5)\n",
    "    calib.fit(X_cal, y_cal)\n",
    "    p_te = calib.predict_proba(X_te)[:, 1]\n",
    "\n",
    "    # --- Regressor (train on train+cal) ---\n",
    "    reg = lgb.LGBMRegressor(\n",
    "        n_estimators=600,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.9,\n",
    "        random_state=42\n",
    "    )\n",
    "    reg.fit(pd.concat([X_tr, X_cal]), y_temp_trcal)\n",
    "    yhat_te = reg.predict(X_te)\n",
    "\n",
    "    # --- Metrics ---\n",
    "    metrics = {\n",
    "        \"AUROC\":  float(roc_auc_score(y_te, p_te)),\n",
    "        \"AUPRC\":  float(average_precision_score(y_te, p_te)),\n",
    "        \"Brier\":  float(brier_score_loss(y_te, p_te)),\n",
    "        \"MAE_temp\": float(mean_absolute_error(y_temp_te, yhat_te))\n",
    "    }\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"H={H}h | AUROC={metrics['AUROC']:.3f}  AUPRC={metrics['AUPRC']:.3f}  \"\n",
    "              f\"Brier={metrics['Brier']:.3f}  MAE_temp={metrics['MAE_temp']:.2f}\")\n",
    "        print(f\"There is a {p_te[-1]*100:.2f}% chance of frost in the next {H} hours, \"\n",
    "              f\"predicted temperature: {yhat_te[-1]:.2f} Â°C\")\n",
    "\n",
    "    return calib, reg, metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6be596e-97c4-4123-a15c-1f15ab1d1b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train/Test on all Names in Dataset\n",
    "for name in datasets:\n",
    "    print(f\"Analyzing {name}'s Dataset ...\")\n",
    "    try:\n",
    "        df = datasets[name]\n",
    "        _calib, _reg6, _metrics6 = train_for_horizon(df, H=6, verbose=True)\n",
    "    except NameError:\n",
    "        print(\"Define `df` (your CIMIS DataFrame) before running the example usage cell.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ab6710-3d69-4e10-8a08-18cd0029e1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_src_test_tgt(src: str, tgt: str, H: int = 6):\n",
    "    # 1) Build source XY and remember the EXACT feature list used\n",
    "    X_src, y_frost_src, y_temp_src, feat_cols = build_xy(datasets[src], H)\n",
    "    \n",
    "    # 2) Train your models (example LightGBM + optional calibration)\n",
    "    clf = lgb.LGBMClassifier(\n",
    "        n_estimators=400, max_depth=-1, learning_rate=0.05, subsample=0.8, colsample_bytree=0.9\n",
    "    )\n",
    "    clf.fit(X_src, y_frost_src)\n",
    "    \n",
    "    reg = lgb.LGBMRegressor(\n",
    "        n_estimators=400, max_depth=-1, learning_rate=0.05, subsample=0.8, colsample_bytree=0.9\n",
    "    )\n",
    "    reg.fit(X_src, y_temp_src)\n",
    "    \n",
    "    # (optional) probability calibration â€” fit on source data\n",
    "    # from sklearn.calibration import CalibratedClassifierCV\n",
    "    # calib = CalibratedClassifierCV(clf, method=\"sigmoid\", cv=5).fit(X_src, y_frost_src)\n",
    "    # use `calib` instead of `clf` below if you calibrate\n",
    "    \n",
    "    # 3) Build target XY using the SAME feature order\n",
    "    X_tgt, y_frost_tgt, y_temp_tgt, _ = build_xy(datasets[tgt], H, feature_cols=feat_cols)\n",
    "    \n",
    "    # 4) Evaluate transfer\n",
    "    from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss, mean_absolute_error\n",
    "    \n",
    "    p_tgt   = clf.predict_proba(X_tgt)[:, 1]  # or calib.predict_proba(...)\n",
    "    t_tgt   = reg.predict(X_tgt)\n",
    "    \n",
    "    print(f\"Trained on {src}  â†’  Tested on {tgt}\")\n",
    "    print(f\"AUROC={roc_auc_score(y_frost_tgt, p_tgt):.3f}  \"\n",
    "          f\"AUPRC={average_precision_score(y_frost_tgt, p_tgt):.3f}  \"\n",
    "          f\"Brier={brier_score_loss(y_frost_tgt, p_tgt):.3f}  \"\n",
    "          f\"MAE_temp={mean_absolute_error(y_temp_tgt, t_tgt):.2f} Â°C\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9cb530-fe78-4ddb-bcaa-4e7761d4c6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hr TimeFrame Prediction/Classification\n",
    "H = 24\n",
    "\n",
    "# pick source and target stations\n",
    "src = \"105-westlands\"\n",
    "tgt = \"80-fresnostate\"\n",
    "\n",
    "train_src_test_tgt(src, tgt, H)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "lightgbm_integration": {
   "appended_at": "2025-11-17T03:27:25.431377Z"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
